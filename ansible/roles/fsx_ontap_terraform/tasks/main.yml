---
# fsx_ontap_terraform role
#
# Creates an FSx for NetApp ONTAP file system via Terraform.
# Expects cluster_info dict (from cluster_discovery role) and fsx_admin_password.
# Terraform runs inside a container (podman/docker).
#
# The file_system_name defaults to: <cluster_name>-<region>-fsx
#
# Modes:
#   fsx_prepare_only: false (default) - full lifecycle: setup, init, plan, apply, outputs
#   fsx_prepare_only: true            - setup, init, plan only; exports fsx_prepared fact
#                                       for the caller to run apply in parallel

- name: "{{ fsx_label }} - Compute file system name"
  set_fact:
    file_system_name: >-
      {{ file_system_name_override | default('') | trim
         if (file_system_name_override | default('') | trim) != ''
         else (cluster_info.cluster_name ~ '-' ~ cluster_info.region ~ '-fsx') }}

- name: "{{ fsx_label }} - Set working directory"
  set_fact:
    _fsx_workdir: "{{ fsx_tf_workdir_base }}/{{ file_system_name }}"
    _terraform_state_key: "fsx-ontap/{{ cluster_info.cluster_name }}/{{ cluster_info.region }}/terraform.tfstate"

- name: "{{ fsx_label }} - Display configuration"
  debug:
    msg:
      - "=========================================="
      - "FSx ONTAP Terraform - {{ fsx_label }}"
      - "=========================================="
      - "File System Name: {{ file_system_name }}"
      - "Region: {{ cluster_info.region }}"
      - "VPC ID: {{ cluster_info.vpc_id }}"
      - "Subnets: {{ cluster_info.subnet_ids[:2] }}"
      - "Route Tables: {{ cluster_info.route_table_ids }}"
      - "Operation: {{ 'DESTROY' if (terraform_destroy | default(false)) else 'APPLY' }}{{ ' (prepare only)' if (fsx_prepare_only | default(false)) else '' }}"
      - "Working Dir: {{ _fsx_workdir }}"
      - "Container: {{ terraform_image }}"
      - "=========================================="

# Get AWS credentials (needed for both create and destroy, and for bucket check)
- name: "{{ fsx_label }} - Get AWS credentials from boto3 session"
  ansible.builtin.shell: |
    python3 -c "
    import json, boto3
    creds = boto3.Session().get_credentials().get_frozen_credentials()
    print(json.dumps({'ak': creds.access_key, 'sk': creds.secret_key, 'st': creds.token or ''}))
    "
  register: _boto3_creds
  changed_when: false

- name: "{{ fsx_label }} - Set AWS credentials"
  set_fact:
    _aws_creds: "{{ _boto3_creds.stdout | from_json }}"
    _aws_env:
      AWS_ACCESS_KEY_ID: "{{ (_boto3_creds.stdout | from_json).ak }}"
      AWS_SECRET_ACCESS_KEY: "{{ (_boto3_creds.stdout | from_json).sk }}"
      AWS_SESSION_TOKEN: "{{ (_boto3_creds.stdout | from_json).st }}"
      AWS_REGION: "{{ terraform_state_region | default(cluster_info.region) }}"
      AWS_DEFAULT_REGION: "{{ terraform_state_region | default(cluster_info.region) }}"

# ---------------------------------------------------------------------------
# Pre-flight: verify the S3 state bucket exists before running terraform.
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Check if S3 state bucket exists"
  ansible.builtin.shell: >-
    aws s3api head-bucket --bucket {{ terraform_state_bucket }} 2>/dev/null
    && echo "exists" || echo "missing"
  register: _state_bucket_check
  changed_when: false
  environment: "{{ _aws_env }}"
  when: terraform_state_bucket | default('') | length > 0

- name: "{{ fsx_label }} - Set state bucket availability flag"
  set_fact:
    _state_bucket_available: >-
      {{ (terraform_state_bucket | default('') | length > 0) and
         (_state_bucket_check.stdout | default('missing') is search('exists')) }}

- name: "{{ fsx_label }} - Skip - S3 state bucket does not exist"
  debug:
    msg:
      - "S3 state bucket '{{ terraform_state_bucket }}' does not exist."
      - "Skipping {{ 'destroy' if (terraform_destroy | default(false)) else 'apply' }} for {{ file_system_name }}."
      - "If you need to clean up orphaned resources, do so manually in the AWS console."
  when: not _state_bucket_available and (terraform_state_bucket | default('') | length > 0)

# Set skipped prepared fact when bucket is missing (so callers don't fail)
- name: "{{ fsx_label }} - Set skipped prepared fact"
  set_fact:
    fsx_prepared:
      skipped: true
      file_system_name: "{{ file_system_name }}"
      label: "{{ fsx_label }}"
  when:
    - fsx_prepare_only | default(false)
    - not _state_bucket_available
    - terraform_state_bucket | default('') | length > 0

# ---------------------------------------------------------------------------
# Common setup (runs for both create and destroy when state bucket is available)
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Setup terraform workspace"
  when: _state_bucket_available or (terraform_state_bucket | default('') | length == 0)
  block:
    - name: "{{ fsx_label }} - Create terraform working directory"
      file:
        path: "{{ _fsx_workdir }}"
        state: directory
        mode: '0755'

    - name: "{{ fsx_label }} - Copy terraform files to working directory"
      copy:
        src: "{{ fsx_tf_source }}/{{ item }}"
        dest: "{{ _fsx_workdir }}/{{ item }}"
        mode: '0644'
      loop:
        - main.tf
        - variables.tf
        - outputs.tf
        - providers.tf

    - name: "{{ fsx_label }} - Check if S3 backend is configured"
      set_fact:
        _use_s3_backend: "{{ terraform_state_bucket | default('') | length > 0 }}"

    - name: "{{ fsx_label }} - Generate backend.tf for S3 state"
      template:
        src: backend.tf.j2
        dest: "{{ _fsx_workdir }}/backend.tf"
        mode: '0644'
      when: _use_s3_backend

    - name: "{{ fsx_label }} - Remove backend.tf if not using S3"
      file:
        path: "{{ _fsx_workdir }}/backend.tf"
        state: absent
      when: not _use_s3_backend

    - name: "{{ fsx_label }} - Generate terraform.tfvars"
      template:
        src: terraform.tfvars.j2
        dest: "{{ _fsx_workdir }}/terraform.tfvars"
        mode: '0600'
      when: not (terraform_destroy | default(false))

    # Build the container terraform command prefix
    - name: "{{ fsx_label }} - Build terraform container command"
      set_fact:
        _tf_cmd: >-
          {{ container_runtime }} run --rm
          -v {{ _fsx_workdir }}:/workspace:Z
          -w /workspace
          -e AWS_ACCESS_KEY_ID={{ _aws_creds.ak }}
          -e AWS_SECRET_ACCESS_KEY={{ _aws_creds.sk }}
          {% if _aws_creds.st %}-e AWS_SESSION_TOKEN={{ _aws_creds.st }}{% endif %}
          -e AWS_REGION={{ cluster_info.region }}
          -e AWS_DEFAULT_REGION={{ cluster_info.region }}
          {{ terraform_image }}

    - name: "{{ fsx_label }} - Initialize Terraform"
      ansible.builtin.shell: "{{ _tf_cmd }} terraform init -upgrade -reconfigure -no-color"
      register: _tf_init
      changed_when: "'Terraform has been successfully initialized' in _tf_init.stdout"

    # -----------------------------------------------------------------
    # Idempotency: import / clean up resources that exist in AWS but
    # are not in terraform state (e.g. from a previous partial run or
    # after the state bucket was recreated).
    #
    # Strategy:
    #   SG       – import it, then revoke all its rules so Terraform
    #              can (re)create them cleanly.
    #   Secrets  – import the secret; Terraform will push a new
    #              version during apply.
    #   FSx / SVM – import if found (long-lived, expensive resources).
    # -----------------------------------------------------------------
    - name: "{{ fsx_label }} - Check terraform state"
      ansible.builtin.shell: "{{ _tf_cmd }} terraform state list 2>/dev/null"
      register: _tf_state_list
      changed_when: false
      failed_when: false

    - name: "{{ fsx_label }} - Check for existing resources to import"
      when: "'aws_security_group.fsx_ontap' not in (_tf_state_list.stdout | default(''))"
      block:
        # ---- Look up existing AWS resources ---------------------
        - name: "{{ fsx_label }} - Look up existing security group"
          ansible.builtin.shell: >-
            aws ec2 describe-security-groups
            --filters Name=group-name,Values={{ file_system_name }}-sg
            Name=vpc-id,Values={{ cluster_info.vpc_id }}
            --query 'SecurityGroups[0].GroupId' --output text
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          register: _existing_sg
          changed_when: false
          failed_when: false

        - name: "{{ fsx_label }} - Look up existing FSx admin secret"
          ansible.builtin.shell: >-
            aws secretsmanager describe-secret
            --secret-id {{ file_system_name }}-FsxAdminPassword
            --query 'ARN' --output text
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          register: _existing_fsx_secret
          changed_when: false
          failed_when: false

        - name: "{{ fsx_label }} - Look up existing SVM admin secret"
          ansible.builtin.shell: >-
            aws secretsmanager describe-secret
            --secret-id {{ file_system_name }}-SVMAdminPassword
            --query 'ARN' --output text
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          register: _existing_svm_secret
          changed_when: false
          failed_when: false

        - name: "{{ fsx_label }} - Look up existing FSx filesystem"
          ansible.builtin.shell: >-
            aws fsx describe-file-systems
            --query "FileSystems[?Tags[?Key=='Name'&&Value=='{{ file_system_name }}']].FileSystemId | [0]"
            --output text
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          register: _existing_fsx
          changed_when: false
          failed_when: false

        - name: "{{ fsx_label }} - Look up existing SVM"
          ansible.builtin.shell: >-
            aws fsx describe-storage-virtual-machines
            --query "StorageVirtualMachines[?FileSystemId=='{{ _existing_fsx.stdout | trim }}'].StorageVirtualMachineId | [0]"
            --output text
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          register: _existing_svm
          changed_when: false
          failed_when: false
          when: _existing_fsx.rc == 0 and _existing_fsx.stdout | trim not in ['None', '']

        # ---- Build and run import script -------------------------
        - name: "{{ fsx_label }} - Set import flags"
          set_fact:
            _sg_exists: "{{ _existing_sg.rc == 0 and _existing_sg.stdout | trim not in ['None', ''] }}"
            _fsx_secret_exists: "{{ _existing_fsx_secret.rc == 0 and _existing_fsx_secret.stdout | trim not in ['None', ''] }}"
            _svm_secret_exists: "{{ _existing_svm_secret.rc == 0 and _existing_svm_secret.stdout | trim not in ['None', ''] }}"
            _fsx_exists: "{{ _existing_fsx.rc | default(1) == 0 and _existing_fsx.stdout | default('None') | trim not in ['None', ''] }}"
            _svm_exists: "{{ _existing_svm.rc | default(1) == 0 and _existing_svm.stdout | default('None') | trim not in ['None', ''] }}"

        - name: "{{ fsx_label }} - Generate import script"
          copy:
            dest: "{{ _fsx_workdir }}/import.sh"
            mode: '0755'
            content: |
              #!/bin/sh
              set -e
              {% if _sg_exists | bool %}
              echo "=== Importing security group {{ _existing_sg.stdout | trim }} ==="
              terraform import -no-color aws_security_group.fsx_ontap {{ _existing_sg.stdout | trim }} || true
              {% endif %}
              {% if _fsx_secret_exists | bool %}
              echo "=== Importing FSx admin secret ==="
              terraform import -no-color 'aws_secretsmanager_secret.fsx_admin[0]' '{{ _existing_fsx_secret.stdout | trim }}' || true
              {% endif %}
              {% if _svm_secret_exists | bool %}
              echo "=== Importing SVM admin secret ==="
              terraform import -no-color 'aws_secretsmanager_secret.svm_admin[0]' '{{ _existing_svm_secret.stdout | trim }}' || true
              {% endif %}
              {% if _fsx_exists | bool %}
              echo "=== Importing FSx filesystem {{ _existing_fsx.stdout | trim }} ==="
              terraform import -no-color aws_fsx_ontap_file_system.this {{ _existing_fsx.stdout | trim }} || true
              {% endif %}
              {% if _svm_exists | bool %}
              echo "=== Importing SVM {{ _existing_svm.stdout | trim }} ==="
              terraform import -no-color aws_fsx_ontap_storage_virtual_machine.this {{ _existing_svm.stdout | trim }} || true
              {% endif %}
              echo "=== FSx import complete ==="
          when: (_sg_exists | bool) or (_fsx_secret_exists | bool) or (_svm_secret_exists | bool) or (_fsx_exists | bool)

        - name: "{{ fsx_label }} - Run import script"
          ansible.builtin.shell: "{{ _tf_cmd }} sh /workspace/import.sh"
          register: _import_result
          when: (_sg_exists | bool) or (_fsx_secret_exists | bool) or (_svm_secret_exists | bool) or (_fsx_exists | bool)

        - name: "{{ fsx_label }} - Display import results"
          debug:
            msg: "{{ _import_result.stdout_lines | default(['No imports needed']) }}"

        - name: "{{ fsx_label }} - Clean up import script"
          file:
            path: "{{ _fsx_workdir }}/import.sh"
            state: absent

        # ---- Delete orphaned SG rules so Terraform can recreate them ----
        # (SG rules are separate terraform resources; importing the SG
        #  does NOT import its rules. Deleting them avoids "Duplicate" errors.)
        - name: "{{ fsx_label }} - Get all existing SG rule IDs"
          ansible.builtin.shell: >-
            aws ec2 describe-security-group-rules
            --filters Name=group-id,Values={{ _existing_sg.stdout | trim }}
            --query 'SecurityGroupRules[].{Id:SecurityGroupRuleId,IsEgress:IsEgress}'
            --output json
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          register: _sg_rules_raw
          changed_when: false
          failed_when: false
          when: _sg_exists | bool

        - name: "{{ fsx_label }} - Parse SG rules"
          set_fact:
            _sg_ingress_rule_ids: >-
              {{ (_sg_rules_raw.stdout | default('[]') | from_json)
                 | rejectattr('IsEgress') | map(attribute='Id') | list }}
            _sg_egress_rule_ids: >-
              {{ (_sg_rules_raw.stdout | default('[]') | from_json)
                 | selectattr('IsEgress') | map(attribute='Id') | list }}
          when: _sg_exists | bool

        - name: "{{ fsx_label }} - Revoke orphaned ingress rules"
          ansible.builtin.shell: >-
            aws ec2 revoke-security-group-ingress
            --group-id {{ _existing_sg.stdout | trim }}
            --security-group-rule-ids {{ _sg_ingress_rule_ids | join(' ') }}
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          failed_when: false
          when:
            - _sg_exists | bool
            - (_sg_ingress_rule_ids | default([]) | length) > 0

        - name: "{{ fsx_label }} - Revoke orphaned egress rules"
          ansible.builtin.shell: >-
            aws ec2 revoke-security-group-egress
            --group-id {{ _existing_sg.stdout | trim }}
            --security-group-rule-ids {{ _sg_egress_rule_ids | join(' ') }}
            --region {{ cluster_info.region }}
          environment: "{{ _aws_env }}"
          failed_when: false
          when:
            - _sg_exists | bool
            - (_sg_egress_rule_ids | default([]) | length) > 0

        # Secrets are imported (not deleted). Terraform's PutSecretValue for
        # aws_secretsmanager_secret_version will create a new version, which
        # works even when a version already exists.

# ---------------------------------------------------------------------------
# Create: Plan phase (runs in both normal and prepare_only mode)
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Terraform plan"
  ansible.builtin.shell: "{{ _tf_cmd }} terraform plan -out=tfplan -input=false -no-color"
  register: _tf_plan
  when:
    - not (terraform_destroy | default(false))
    - _state_bucket_available or (terraform_state_bucket | default('') | length == 0)

# ---------------------------------------------------------------------------
# Destroy: Plan phase (runs in both normal and prepare_only mode)
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Terraform destroy plan"
  ansible.builtin.shell: "{{ _tf_cmd }} terraform plan -destroy -out=tfplan-destroy -input=false -no-color"
  when:
    - terraform_destroy | default(false)
    - _state_bucket_available or (terraform_state_bucket | default('') | length == 0)

# ---------------------------------------------------------------------------
# Prepare-only mode: export everything needed for the caller to run apply
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Export prepared state for parallel apply"
  set_fact:
    fsx_prepared:
      skipped: false
      tf_cmd: "{{ _tf_cmd }}"
      workdir: "{{ _fsx_workdir }}"
      file_system_name: "{{ file_system_name }}"
      label: "{{ fsx_label }}"
      apply_cmd: >-
        {{ _tf_cmd }} terraform apply -auto-approve -no-color
        {{ 'tfplan-destroy' if (terraform_destroy | default(false)) else 'tfplan' }}
      output_cmd: "{{ _tf_cmd }} terraform output -json -no-color"
      is_destroy: "{{ terraform_destroy | default(false) }}"
  when:
    - fsx_prepare_only | default(false)
    - _state_bucket_available or (terraform_state_bucket | default('') | length == 0)

# ---------------------------------------------------------------------------
# Full mode: Apply (only when not prepare_only)
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Apply terraform"
  when:
    - not (fsx_prepare_only | default(false))
    - not (terraform_destroy | default(false))
    - _state_bucket_available or (terraform_state_bucket | default('') | length == 0)
  block:
    - name: "{{ fsx_label }} - Terraform apply"
      ansible.builtin.shell: "{{ _tf_cmd }} terraform apply -auto-approve -no-color tfplan"
      register: _tf_apply

    - name: "{{ fsx_label }} - Get Terraform outputs"
      ansible.builtin.shell: "{{ _tf_cmd }} terraform output -json -no-color"
      register: _tf_outputs_raw
      changed_when: false

    - name: "{{ fsx_label }} - Parse Terraform outputs"
      set_fact:
        _tf_outputs: "{{ _tf_outputs_raw.stdout | from_json }}"
      when: _tf_outputs_raw.stdout is defined

    - name: "{{ fsx_label }} - Set output facts"
      set_fact:
        fsx_result:
          file_system_id: "{{ _tf_outputs.file_system_id.value }}"
          file_system_dns_name: "{{ _tf_outputs.file_system_dns_name.value }}"
          svm_id: "{{ _tf_outputs.svm_id.value }}"
          svm_name: "{{ _tf_outputs.svm_name.value }}"
          svm_mgmt_dns_name: "{{ _tf_outputs.svm_management_endpoint_dns_name.value | default('') }}"
          intercluster_dns_name: "{{ _tf_outputs.intercluster_endpoint_dns_name.value | default('') }}"
          intercluster_ips: "{{ _tf_outputs.intercluster_endpoint_ip_addresses.value | default([]) }}"
          security_group_id: "{{ _tf_outputs.security_group_id.value }}"
          file_system_name: "{{ file_system_name }}"
      when: _tf_outputs is defined

    - name: "{{ fsx_label }} - Display Output Summary"
      debug:
        msg:
          - "=========================================="
          - "FSx for ONTAP Deployment Complete"
          - "=========================================="
          - "File System Name: {{ fsx_result.file_system_name }}"
          - "File System ID: {{ fsx_result.file_system_id }}"
          - "File System DNS: {{ fsx_result.file_system_dns_name }}"
          - "SVM ID: {{ fsx_result.svm_id }}"
          - "SVM Name: {{ fsx_result.svm_name }}"
          - "SVM Management DNS: {{ fsx_result.svm_mgmt_dns_name }}"
          - "Intercluster DNS: {{ fsx_result.intercluster_dns_name }}"
          - "Intercluster IPs: {{ fsx_result.intercluster_ips }}"
          - "Security Group ID: {{ fsx_result.security_group_id }}"
          - "=========================================="
      when: fsx_result is defined

# ---------------------------------------------------------------------------
# Full mode: Destroy (only when not prepare_only)
# ---------------------------------------------------------------------------
- name: "{{ fsx_label }} - Destroy terraform resources"
  when:
    - not (fsx_prepare_only | default(false))
    - terraform_destroy | default(false)
    - _state_bucket_available or (terraform_state_bucket | default('') | length == 0)
  block:
    - name: "{{ fsx_label }} - Terraform destroy"
      ansible.builtin.shell: "{{ _tf_cmd }} terraform apply -auto-approve -no-color tfplan-destroy"

    - name: "{{ fsx_label }} - Display destroy completion"
      debug:
        msg:
          - "=========================================="
          - "FSx for ONTAP Resources Destroyed: {{ file_system_name }}"
          - "=========================================="
